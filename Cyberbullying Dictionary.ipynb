{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b148a67d-2a73-425b-8d9d-0a247bc93efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38bbc53f-e191-463a-b7f4-17d6a7aed9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe319779-1ead-4f1e-846e-146017c9fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('CyTweets.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbcfaabc-38c7-4930-91d4-34ce68dd4b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text         UserName  \\\n",
      "0    Dj Warras uyanya! he's speaking from a point o...       AMGLOUNGE_   \n",
      "1    Never : Ayanda Thabethe buying Rolls- Royce \\n...       _Dlamini24   \n",
      "2        Uyanya wena it's not at limpopo its at Brasil      MatsobaneMo   \n",
      "3    @Vhoyde Ozempic face. uOprah akaguli uyanya ng...     LordBae_Less   \n",
      "4    @BoyyyBaby5100 Uyanya that's not your slip. Yo...  AubreyMaha57923   \n",
      "..                                                 ...              ...   \n",
      "605  RT @Tesla: FSD Supervised can navigate complex...         elonmusk   \n",
      "606  RT @Teslaconomics: People laugh at me, till th...         elonmusk   \n",
      "607  RT @cb_doge: Why Political Advertisers should ...         elonmusk   \n",
      "608                                Flight 5 in 4 weeks         elonmusk   \n",
      "609                        Wise words from @AriEmanuel         elonmusk   \n",
      "\n",
      "                 Location  \n",
      "0            South Africa  \n",
      "1                     NaN  \n",
      "2            South Africa  \n",
      "3          Dubai, U. A. E  \n",
      "4    Soweto, South Africa  \n",
      "..                    ...  \n",
      "605                   NaN  \n",
      "606                   NaN  \n",
      "607                   NaN  \n",
      "608                   NaN  \n",
      "609                   NaN  \n",
      "\n",
      "[610 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68fb8fb2-1f35-4b4f-8d94-776376c1863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e66fe51-ca1b-47a3-b202-81ea49e82d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyberbullying_dict = { \n",
    "    'uyanya':'Cyberbullying',\n",
    "    'msunu':'Cyberbullying',\n",
    "    'mnqundu':'Cyberbullying',\n",
    "    'uyanuka':'Cyberbullying',\n",
    "    'gqwirha':'Cyberbullying',\n",
    "}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a79454a-156a-4d4b-80a1-20aaded3a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text         UserName  \\\n",
      "0    Dj Warras uyanya! he's speaking from a point o...       AMGLOUNGE_   \n",
      "1    Never : Ayanda Thabethe buying Rolls- Royce \\n...       _Dlamini24   \n",
      "2        Uyanya wena it's not at limpopo its at Brasil      MatsobaneMo   \n",
      "3    @Vhoyde Ozempic face. uOprah akaguli uyanya ng...     LordBae_Less   \n",
      "4    @BoyyyBaby5100 Uyanya that's not your slip. Yo...  AubreyMaha57923   \n",
      "..                                                 ...              ...   \n",
      "605  RT @Tesla: FSD Supervised can navigate complex...         elonmusk   \n",
      "606  RT @Teslaconomics: People laugh at me, till th...         elonmusk   \n",
      "607  RT @cb_doge: Why Political Advertisers should ...         elonmusk   \n",
      "608                                Flight 5 in 4 weeks         elonmusk   \n",
      "609                        Wise words from @AriEmanuel         elonmusk   \n",
      "\n",
      "                 Location              Label  \n",
      "0            South Africa      Cyberbullying  \n",
      "1                     NaN      Cyberbullying  \n",
      "2            South Africa      Cyberbullying  \n",
      "3          Dubai, U. A. E      Cyberbullying  \n",
      "4    Soweto, South Africa      Cyberbullying  \n",
      "..                    ...                ...  \n",
      "605                   NaN  Not Cyberbullying  \n",
      "606                   NaN  Not Cyberbullying  \n",
      "607                   NaN  Not Cyberbullying  \n",
      "608                   NaN  Not Cyberbullying  \n",
      "609                   NaN  Not Cyberbullying  \n",
      "\n",
      "[610 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    " def label_text(text, keyword_dict):\n",
    "    \"\"\"\n",
    "    Label text based on the presence of keywords from the dictionary.\n",
    "    Args:\n",
    "    - text (str): The text to be labeled.\n",
    "    - keyword_dict (dict): Dictionary containing keywords and their labels.\n",
    "    Returns:\n",
    "    - str: The label if any keyword is found, otherwise 'Not Cyberbullying'.\n",
    "    \"\"\"\n",
    "    for keyword in keyword_dict:\n",
    "        if keyword in text.lower():\n",
    "            return keyword_dict[keyword]\n",
    "    return 'Not Cyberbullying'\n",
    " \n",
    "# Apply labeling function to the 'Text' column\n",
    "df['Label'] = df['text'].apply(lambda x: label_text(x, cyberbullying_dict))\n",
    " \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85df096d-44bc-49b1-836d-b70a806cd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f143722c-aff1-4f01-a74d-24c461a71d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function to clean the tweet text\n",
    "    \"\"\"\n",
    "    #Remove hyper links\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', ' ', text)\n",
    "    \n",
    "    #Remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
    "    \n",
    "    #Remove anything that isn't a letter, number, or one of the punctuation marks listed\n",
    "    text = re.sub(r\"[^A-Za-z0-9#'?!,.]+\", ' ', text)   \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a260f5-752d-43a8-b7c5-08f8cfd89a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the clean_text function to the 'tweet_text' column\n",
    "df['text']=df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea0686d6-1699-4de1-b73a-54fe337440ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dj Warras uyanya! he's speaking from a point of half white privilege #DJWarrasmustfall  \n",
      "\n",
      "2 Never Ayanda Thabethe buying Rolls Royce UYANYA  \n",
      "\n",
      "3 Uyanya wena it's not at limpopo its at Brasil \n",
      "\n",
      "4  Ozempic face. uOprah akaguli uyanya ngoku zezishortcut  \n",
      "\n",
      "5  Uyanya that's not your slip. You don't even have followers. Tsek scam \n",
      "\n",
      "6 dont worry abt this  \n",
      "\n",
      "7 What was she thinking?, uyanya lo.. Divorce loading..  \n",
      "\n",
      "8  Uyanya wena msunuwenja. Selajayezwa kakhulu. Xamu. \n",
      "\n",
      "9 Uyanya wena it can buy unyoko \n",
      "\n",
      "10 Uyanya.. You are fucken crazy.. White don't use their money for business. The banks gives them the money and they buy expensive homes and cars and boats and go on holiday with their 50 million. \n",
      "\n",
      "11 Uyanya ha o hlanya wa hlanya \n",
      "\n",
      "12  Uyanya msunu wenja \n",
      "\n",
      "13  dont worry about this  \n",
      "\n",
      "14   \n",
      "\n",
      "15 uyanya wena \n",
      "\n",
      "16  cabonena Uyanya msunu kanyoko \n",
      "\n",
      "17 Uyanya u J Molley! \n",
      "\n",
      "18  Uyanya wena Msunu  \n",
      "\n",
      "19  Musunu, swina, kubuhlungu, mdidi, mtshaza, abasifuni, uyanya,...... mina bangfundisinhlamba kupela. \n",
      "\n",
      "20 Mara she ate okes uyanya loya thisa wase primary.. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,tweet in enumerate(df['text'].head(20)):\n",
    "    print(i+1, tweet, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f850b78-4dcd-4687-87ad-10504e4247a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Location</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dj warras uyanya! he's speaking from a point o...</td>\n",
       "      <td>AMGLOUNGE_</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>never ayanda thabethe buying rolls royce uyanya</td>\n",
       "      <td>_Dlamini24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uyanya wena it's not at limpopo its at brasil</td>\n",
       "      <td>MatsobaneMo</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ozempic face. uoprah akaguli uyanya ngoku zez...</td>\n",
       "      <td>LordBae_Less</td>\n",
       "      <td>Dubai, U. A. E</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uyanya that's not your slip. you don't even h...</td>\n",
       "      <td>AubreyMaha57923</td>\n",
       "      <td>Soweto, South Africa</td>\n",
       "      <td>Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>rt fsd supervised can navigate complex city tr...</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>rt people laugh at me, till they find out what...</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>rt doge why political advertisers should choos...</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>flight 5 in 4 weeks</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>wise words from</td>\n",
       "      <td>elonmusk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text         UserName  \\\n",
       "0    dj warras uyanya! he's speaking from a point o...       AMGLOUNGE_   \n",
       "1     never ayanda thabethe buying rolls royce uyanya        _Dlamini24   \n",
       "2        uyanya wena it's not at limpopo its at brasil      MatsobaneMo   \n",
       "3     ozempic face. uoprah akaguli uyanya ngoku zez...     LordBae_Less   \n",
       "4     uyanya that's not your slip. you don't even h...  AubreyMaha57923   \n",
       "..                                                 ...              ...   \n",
       "605  rt fsd supervised can navigate complex city tr...         elonmusk   \n",
       "606  rt people laugh at me, till they find out what...         elonmusk   \n",
       "607  rt doge why political advertisers should choos...         elonmusk   \n",
       "608                                flight 5 in 4 weeks         elonmusk   \n",
       "609                                   wise words from          elonmusk   \n",
       "\n",
       "                 Location              Label  \n",
       "0            South Africa      Cyberbullying  \n",
       "1                     NaN      Cyberbullying  \n",
       "2            South Africa      Cyberbullying  \n",
       "3          Dubai, U. A. E      Cyberbullying  \n",
       "4    Soweto, South Africa      Cyberbullying  \n",
       "..                    ...                ...  \n",
       "605                   NaN  Not Cyberbullying  \n",
       "606                   NaN  Not Cyberbullying  \n",
       "607                   NaN  Not Cyberbullying  \n",
       "608                   NaN  Not Cyberbullying  \n",
       "609                   NaN  Not Cyberbullying  \n",
       "\n",
       "[610 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d6c9fe-9a1e-41e6-aa0e-ca46bac666b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vpmatomela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc546db3-af3a-42ee-b780-68db582bd41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9398907103825137\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    Cyberbullying       1.00      0.83      0.90        63\n",
      "Not Cyberbullying       0.92      1.00      0.96       120\n",
      "\n",
      "         accuracy                           0.94       183\n",
      "        macro avg       0.96      0.91      0.93       183\n",
      "     weighted avg       0.94      0.94      0.94       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    " \n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    " \n",
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    " \n",
    "# Initialize and train Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    " \n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    " \n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a45fbdd-c110-4baa-99fa-e1e791839c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9890710382513661\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Cyberbullying       1.00      0.97      0.98        63\n",
      "Not Cyberbullying       0.98      1.00      0.99       120\n",
      "\n",
      "         accuracy                           0.99       183\n",
      "        macro avg       0.99      0.98      0.99       183\n",
      "     weighted avg       0.99      0.99      0.99       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    " \n",
    " \n",
    "# Prepare data\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    " \n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    " \n",
    "# Train model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_vec, y_train)\n",
    " \n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723e261-3ab6-4554-91b9-f32c3c65acfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
